{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from pprint import pprint\n",
    "from prettytable import PrettyTable\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from scipy.stats import mode\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_sub= pd.read_csv('forest/naive_submission.csv')\n",
    "df= pd.read_csv('forest/train.csv').drop('Unnamed: 0',axis=1)\n",
    "test= pd.read_csv('forest/test.csv').drop('row_ID',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable qualitative ou quantitative\n",
    "# Toutes les variables sont quantitatives, à part Soil_Type et Wilderness_Area\n",
    "columns= df.columns\n",
    "quantitative_vars = columns[:10]\n",
    "qual_vars = columns[10:]\n",
    "qualitative_vars = [item.rsplit('_')[1] for item in qual_vars if item != 'Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtre les données en fonction des quantiles calculés pour chaque variable\n",
    "# Définition d'un nouveau dataframe df_filtered\n",
    "df_filtered = df.copy()\n",
    "\n",
    "for col in quantitative_vars:\n",
    "    Q3 = df_filtered[col].quantile(0.85)\n",
    "    Q1 = df_filtered[col].quantile(0.15)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_filtered = df_filtered[(df_filtered[col] >= lower_bound) & (df_filtered[col] <= upper_bound)]\n",
    "df_filtered_long = pd.melt(df_filtered, var_name='Variables', value_name='Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des données\n",
    "ct_s = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('standardize', StandardScaler(), quantitative_vars)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "df_filtered_ss = ct_s.fit_transform(df_filtered)\n",
    "df_filtered_ss = pd.DataFrame(df_filtered_ss, columns=df_filtered.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering: À Lancer!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = pd.DataFrame()\n",
    "# Distance to hydrology\n",
    "df_fe['Distance_To_Hydrology'] = np.sqrt(df_filtered['Horizontal_Distance_To_Hydrology']**2 + df_filtered['Vertical_Distance_To_Hydrology']**2)\n",
    "df_fe['Distance_To_Hydrology'] = df_fe['Distance_To_Hydrology'].astype(float)\n",
    "\n",
    "# Elevation to Aspect\n",
    "df_fe['Elevation_Aspect'] = df_filtered['Elevation']*np.sin(np.radians(df_filtered['Aspect']))\n",
    "df_fe['Elevation_Aspect'] = df_fe['Elevation_Aspect'].astype(float)\n",
    "\n",
    "# Entrainement d'un modèle basé sur Soil Type et Wilderness Area\n",
    "\n",
    "# Encode `Soil_Type` et `Wilderness_Area` comme une catégorie\n",
    "soil_columns = [col for col in df_filtered.columns if col.startswith('Soil_Type')]\n",
    "area_columns = [col for col in df_filtered.columns if col.startswith('Wilderness_Area')]\n",
    "X_sw = df_filtered[soil_columns+area_columns].drop('Soil_Type15',axis=1)\n",
    "y_sw = df_filtered['Cover_Type']\n",
    "\n",
    "model_sw = RandomForestClassifier(random_state=42)\n",
    "model_sw.fit(X_sw, y_sw)\n",
    "\n",
    "df_fe['Soil_Wilderness_Predict'] = model_sw.predict(X_sw)\n",
    "df_fe['Soil_Wilderness_Predict'] = df_fe['Soil_Wilderness_Predict'].astype(str)\n",
    "df_fe['Soil_Wilderness_Predict'] = df_fe['Soil_Wilderness_Predict'].astype('category')\n",
    "\n",
    "ct_s2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('standardize', StandardScaler(), ['Distance_To_Hydrology', 'Elevation_Aspect'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Normalisation\n",
    "df_fe_ss = ct_s2.fit_transform(df_fe)\n",
    "df_fe_ss = pd.DataFrame(df_fe_ss, columns=df_fe.columns)\n",
    "\n",
    "# Convertir en numérique les colonnes qui devraient l'être\n",
    "cols_to_numeric = ['Distance_To_Hydrology', 'Elevation_Aspect']\n",
    "for col in cols_to_numeric:\n",
    "    df_fe_ss[col] = pd.to_numeric(df_fe_ss[col], errors='coerce')\n",
    "\n",
    "# Convertir les autres colonnes en type \"category\" pour les colonnes catégorielles\n",
    "cols_to_category = ['Soil_Wilderness_Predict']\n",
    "for col in cols_to_category:\n",
    "    df_fe_ss[col] = df_fe_ss[col].astype('category')\n",
    "\n",
    "# Concanténation\n",
    "df_filtered_ss = df_filtered_ss.join(df_fe_ss)\n",
    "\n",
    "# Matrice de transformations\n",
    "def dataframe_fe(df, model_sw, ct_s, ct_s2):\n",
    "    # Input\n",
    "    # model_sw : Modele pour predire Cover type a partir de Soil Type et Wilderness Area\n",
    "    # ct_s : normalisation utilisé sur donnees train\n",
    "    # ct_s2 : normalisation utilisé sur donnees train feature engineering\n",
    "\n",
    "    # Output\n",
    "    # df_filtered_ss: variables one hot encoded\n",
    "    # df_filtered_ss: variable soil type n'est plus one hot encode\n",
    "\n",
    "    df_fe = pd.DataFrame()\n",
    "    df = df.drop('Soil_Type15', axis=1)\n",
    "    \n",
    "    # Distance to hydrology\n",
    "    df_fe['Distance_To_Hydrology'] = np.sqrt(df['Horizontal_Distance_To_Hydrology']**2 + df['Vertical_Distance_To_Hydrology']**2)\n",
    "    df_fe['Distance_To_Hydrology'] = df_fe['Distance_To_Hydrology'].astype(float)\n",
    "\n",
    "    # Elevation to Aspect\n",
    "    df_fe['Elevation_Aspect'] = df['Elevation']*np.sin(np.radians(df['Aspect']))\n",
    "    df_fe['Elevation_Aspect'] = df_fe['Elevation_Aspect'].astype(float)\n",
    "\n",
    "    # Entrainement d'un modèle basé sur Soil Type et Wilderness Area\n",
    "    # Encode `Soil_Type` et `Wilderness_Area` comme des catégories\n",
    "    soil_columns = [col for col in df.columns if col.startswith('Soil_Type')]\n",
    "    area_columns = [col for col in df.columns if col.startswith('Wilderness_Area')]\n",
    "    X_sw = df[soil_columns+area_columns]\n",
    "\n",
    "    df_fe['Soil_Wilderness_Predict'] = model_sw.predict(X_sw)\n",
    "    df_fe['Soil_Wilderness_Predict'] = df_fe['Soil_Wilderness_Predict'].astype(str)\n",
    "    df_fe['Soil_Wilderness_Predict'] = df_fe['Soil_Wilderness_Predict'].astype('category')\n",
    "\n",
    "    # Normalisation\n",
    "    df_fe_ss = ct_s2.fit_transform(df_fe)\n",
    "    df_fe_ss = pd.DataFrame(df_fe_ss, columns=df_fe.columns)\n",
    "\n",
    "    # Convertir en numérique les colonnes qui devraient l'être\n",
    "    cols_to_numeric = ['Distance_To_Hydrology', 'Elevation_Aspect']\n",
    "    for col in cols_to_numeric:\n",
    "        df_fe_ss[col] = pd.to_numeric(df_fe_ss[col], errors='coerce')\n",
    "\n",
    "    # Convertir les autres colonnes en type \"category\" pour les colonnes catégorielles\n",
    "    cols_to_category = ['Soil_Wilderness_Predict']\n",
    "    for col in cols_to_category:\n",
    "        df_fe_ss[col] = df_fe_ss[col].astype('category')\n",
    "\n",
    "    # Transformé les données\n",
    "    df_filtered_ss = ct_s.fit_transform(df)\n",
    "    df_filtered_ss = pd.DataFrame(df_filtered_ss, columns=df.columns)\n",
    "    df_filtered_ss = df_filtered_ss.join(df_fe_ss)\n",
    "\n",
    "    ### Décoder Soil Type\n",
    "    soil_columns = [col for col in df_filtered_ss.columns if col.startswith('Soil_Type')]\n",
    "\n",
    "    df_filtered_ss['Soil_Type'] = np.argmax(df_filtered_ss[soil_columns].values, axis=1)\n",
    "\n",
    "    # Type catégorie pour pas confondre avec des entiers\n",
    "    df_filtered_ss['Soil_Type'] = df_filtered_ss['Soil_Type'].astype('category')\n",
    "\n",
    "    # Supprimer les anciennes colonnes one-hot encodées\n",
    "    df_filtered_ss = df_filtered_ss.drop(columns=soil_columns)\n",
    "\n",
    "    return df_filtered_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation des hyperparamètre pour une sélection de modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different models\n",
    "\n",
    "# Return the model with the best performance in cross-validation after grid search (hyperparameters that achieve best cv score)\n",
    "def tune_hyperparameters(model, method, param_grid, X_train, y_train, cv_folds, scoring):\n",
    "    stratified_cv = StratifiedKFold(n_splits=cv_folds, shuffle=True)\n",
    "    gs_model = RandomizedSearchCV(model, param_grid, cv=stratified_cv, scoring=scoring, n_jobs=-1, verbose=1)\n",
    "\n",
    "    if method == 'XGBoost':        \n",
    "        gs_model.fit(X_train, y_train-1)\n",
    "    else:\n",
    "        gs_model.fit(X_train, y_train)\n",
    "    return gs_model.best_estimator_, gs_model.best_params_\n",
    "\n",
    "models = {\n",
    "    \"LightGBM\": lgb.LGBMClassifier(is_unbalance=True),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier(enable_categorical=True),\n",
    "    \"Extra Trees Classifier\": ExtraTreesClassifier(class_weight='balanced')\n",
    "}\n",
    "\n",
    "hyperparameter_grids = {\n",
    "    \"LightGBM\": {\n",
    "        'n_estimators': [100, 300, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'max_depth': [-1, 5, 10, 20],\n",
    "        'min_child_samples': [5, 10, 20, 50],\n",
    "        'min_split_gain': [0, 0.1, 0.5, 1],\n",
    "        'num_leaves': [20, 31, 50, 100],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.1, 1],\n",
    "        'reg_lambda': [1, 0.1, 0],\n",
    "        'verbose': [-1]\n",
    "    },\n",
    "    \"Random Forest Classifier\": {\n",
    "        'n_estimators': [100, 300, 500],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'bootstrap': [True]\n",
    "    },\n",
    "\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [100, 300, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 6, 10, 15],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'gamma': [0, 0.5, 1, 5],\n",
    "        'reg_alpha': [0, 0.1, 1],\n",
    "        'reg_lambda': [1, 0.1, 0]\n",
    "    },\n",
    "    \"Extra Trees Classifier\": {\n",
    "        'n_estimators': [100, 300, 500],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'bootstrap': [True]               \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dataframe_fe(df_filtered, model_sw, ct_s, ct_s2)\n",
    "\n",
    "# Les donnees\n",
    "X = df_train.drop('Cover_Type',axis=1)\n",
    "y = df_train['Cover_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement: objectif Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Random Forest Classifier\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "XGBoost\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Extra Trees Classifier\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "cv_folds = 5\n",
    "\n",
    "tuned_models = {}\n",
    "best_params = {}\n",
    "\n",
    "for method,model in models.items():\n",
    "    print(method)\n",
    "    tuned_model, params = tune_hyperparameters(model, method, hyperparameter_grids[method], X, y, cv_folds, scoring='accuracy')\n",
    "    tuned_models[method] = tuned_model\n",
    "    best_params[method] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement: objectif F1 weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Random Forest Classifier\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "XGBoost\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Extra Trees Classifier\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "cv_folds = 5\n",
    "\n",
    "tuned_models_f1 = {}\n",
    "best_params_f1 = {}\n",
    "\n",
    "for method,model in models.items():\n",
    "    print(method)\n",
    "    tuned_model, params = tune_hyperparameters(model, method, hyperparameter_grids[method], X, y, cv_folds, scoring='f1_weighted')\n",
    "    tuned_models_f1[method] = tuned_model\n",
    "    best_params_f1[method] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédictions: vote majoritaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote_ensemble(data, models):\n",
    "    # test_set : soil type one hot encode\n",
    "\n",
    "    # Predictions\n",
    "    predictions = []\n",
    "    for method in models:\n",
    "        print(method)\n",
    "        if method == 'XGBoost':\n",
    "            pred = models[method].predict(data) + 1\n",
    "            predictions.append(list(pred))\n",
    "        else: \n",
    "            pred = models[method].predict(data)\n",
    "            pred = list(map(int, pred))   \n",
    "            predictions.append(pred)\n",
    "    predictions = np.array(predictions).T  # Transpose so that rows are instances\n",
    "    # Calculer le vote majoritaire pour chaque observation\n",
    "    majority_vote_predictions, _ = mode(predictions, axis=1)\n",
    "    \n",
    "    return majority_vote_predictions.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dataframe_fe(test, model_sw, ct_s, ct_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "Random Forest Classifier\n",
      "XGBoost\n",
      "Extra Trees Classifier\n",
      "LightGBM\n",
      "Random Forest Classifier\n",
      "XGBoost\n",
      "Extra Trees Classifier\n"
     ]
    }
   ],
   "source": [
    "predictions = majority_vote_ensemble(X_test, tuned_models)\n",
    "predictions2 = majority_vote_ensemble(X_test, tuned_models_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame()\n",
    "# # results['Unnamed: 0'] = np.arange(len(test))\n",
    "# results['row_ID'] = np.arange(len(test))\n",
    "# results['Cover_Type'] = predictions\n",
    "# results\n",
    "# results.to_csv('results_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance sur les données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "Random Forest Classifier\n",
      "XGBoost\n",
      "Extra Trees Classifier\n",
      "Accuracy score: 0.9953856362615486\n",
      "F1 score: 0.9953874337886743\n"
     ]
    }
   ],
   "source": [
    "predictions_train = majority_vote_ensemble(X, tuned_models)\n",
    "print('Accuracy score:', accuracy_score(y, predictions_train))\n",
    "print('F1 score:', f1_score(y, predictions_train,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarder les modèles pour utilisation ultérieure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporter modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_models(tuned_models, save_path=\"models/\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    for method, model in tuned_models.items():\n",
    "        # nom du fichier\n",
    "\n",
    "        filename = f\"{save_path}{method.replace(' ', '_')}_tuned_model.joblib\"\n",
    "        \n",
    "        # save modèle\n",
    "        joblib.dump(model, filename)\n",
    "\n",
    "        # Message\n",
    "        print(f\"Modèle '{method}' sauvegardé: '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle 'LightGBM' sauvegardé: 'models/LightGBM_tuned_model.joblib'\n",
      "Modèle 'Random Forest Classifier' sauvegardé: 'models/Random_Forest_Classifier_tuned_model.joblib'\n",
      "Modèle 'XGBoost' sauvegardé: 'models/XGBoost_tuned_model.joblib'\n",
      "Modèle 'Extra Trees Classifier' sauvegardé: 'models/Extra_Trees_Classifier_tuned_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "save_all_models(tuned_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = joblib.load(\"tuned_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
